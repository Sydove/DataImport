package kafka

import (
	"context"
	"fmt"
	"sync/atomic"
	"time"

	"github.com/confluentinc/confluent-kafka-go/kafka"
)

// Producer Kafka Producer åŒ…è£…
type Producer struct {
	producer *kafka.Producer
	tracker  *ProducerTracker
}

// NewProducer åˆ›å»º Producer
func NewProducer(config ProducerConfig) (*Producer, error) {
	kafkaConfig := getBaseConfig()

	// è®¾ç½® Producer é…ç½®
	kafkaConfig.SetKey("compression.type", config.CompressionType)
	kafkaConfig.SetKey("batch.size", config.BatchSize)
	kafkaConfig.SetKey("linger.ms", config.LingerMs)
	kafkaConfig.SetKey("acks", config.Acks)
	kafkaConfig.SetKey("queue.buffering.max.messages", 2000000)
	kafkaConfig.SetKey("queue.buffering.max.kbytes", 1048576)
	kafkaConfig.SetKey("enable.idempotence", true)

	producer, err := kafka.NewProducer(kafkaConfig)
	if err != nil {
		return nil, fmt.Errorf("åˆ›å»º Producer å¤±è´¥: %w", err)
	}

	p := &Producer{
		producer: producer,
		tracker: &ProducerTracker{
			maxPending: config.MaxPending,
		},
	}

	// å¯åŠ¨ ACK å¤„ç†
	go p.handleDeliveryReports()

	return p, nil
}

// handleDeliveryReports å¤„ç†æ¶ˆæ¯å‘é€çš„ ACK
func (p *Producer) handleDeliveryReports() {
	for e := range p.producer.Events() {
		switch ev := e.(type) {
		case *kafka.Message:
			if ev.TopicPartition.Error != nil {
				// å‘é€å¤±è´¥
				atomic.AddInt64(&p.tracker.failedCount, 1)
				fmt.Printf("âŒ æ¶ˆæ¯å‘é€å¤±è´¥: %v\n", ev.TopicPartition.Error)
			} else {
				// å‘é€æˆåŠŸ
				atomic.AddInt64(&p.tracker.successCount, 1)
			}
		case kafka.Error:
			fmt.Printf("âš ï¸ Kafka Error: %v\n", ev)
		}
	}
	fmt.Println("ğŸ“¢ Delivery report handler é€€å‡º")
}

// ProduceWithBackpressure å¸¦èƒŒå‹æ§åˆ¶çš„æ¶ˆæ¯å‘é€
func (p *Producer) ProduceWithBackpressure(ctx context.Context, msg *kafka.Message) error {
	// æ£€æŸ¥å¾…ç¡®è®¤æ¶ˆæ¯æ•°é‡
	for {
		sent := atomic.LoadInt64(&p.tracker.sentCount)
		success := atomic.LoadInt64(&p.tracker.successCount)
		failed := atomic.LoadInt64(&p.tracker.failedCount)
		pending := sent - (success + failed)
		queueLen := int64(p.producer.Len())

		// èƒŒå‹æ§åˆ¶ï¼šå¦‚æœå¾…ç¡®è®¤æ¶ˆæ¯æ•°è¶…è¿‡é˜ˆå€¼ï¼Œç­‰å¾…
		if pending >= p.tracker.maxPending || queueLen >= p.tracker.maxPending {
			atomic.AddInt64(&p.tracker.backpressureHit, 1)

			// åªåœ¨ç¬¬ä¸€æ¬¡è§¦å‘èƒŒå‹æ—¶æ‰“å°
			hitCount := atomic.LoadInt64(&p.tracker.backpressureHit)
			if hitCount == 1 || hitCount%100 == 0 {
				fmt.Printf("ğŸ”´ èƒŒå‹è§¦å‘ (ç¬¬ %d æ¬¡): å¾…ç¡®è®¤ %d æ¡ï¼Œé˜Ÿåˆ— %d æ¡ï¼Œç­‰å¾…å¤„ç†...\n",
					hitCount, pending, queueLen)
			}

			select {
			case <-ctx.Done():
				return ctx.Err()
			case <-time.After(10 * time.Millisecond):
				// ç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•
				continue
			}
		}

		// å¾…ç¡®è®¤æ•°é‡åœ¨é˜ˆå€¼å†…ï¼Œå¯ä»¥å‘é€
		break
	}

	// å‘é€æ¶ˆæ¯
	err := p.producer.Produce(msg, nil)
	if err != nil {
		return fmt.Errorf("æäº¤æ¶ˆæ¯å¤±è´¥: %w", err)
	}

	// å‘é€æˆåŠŸï¼Œè®¡æ•° +1
	atomic.AddInt64(&p.tracker.sentCount, 1)
	return nil
}

// Produce æ™®é€šå‘é€ï¼ˆæ— èƒŒå‹æ§åˆ¶ï¼‰
func (p *Producer) Produce(msg *kafka.Message) error {
	err := p.producer.Produce(msg, nil)
	if err != nil {
		return err
	}
	atomic.AddInt64(&p.tracker.sentCount, 1)
	return nil
}

// WaitForCompletion ç­‰å¾…æ‰€æœ‰æ¶ˆæ¯å‘é€å®Œæˆ
func (p *Producer) WaitForCompletion(ctx context.Context) error {
	ticker := time.NewTicker(1 * time.Second)
	defer ticker.Stop()

	startTime := time.Now()
	lastReported := int64(0)

	for {
		sent := atomic.LoadInt64(&p.tracker.sentCount)
		success := atomic.LoadInt64(&p.tracker.successCount)
		failed := atomic.LoadInt64(&p.tracker.failedCount)
		completed := success + failed
		queueLen := p.producer.Len()

		// æ£€æŸ¥æ˜¯å¦å…¨éƒ¨å®Œæˆ
		if sent > 0 && completed == sent && queueLen == 0 {
			elapsed := time.Since(startTime)
			backpressureHits := atomic.LoadInt64(&p.tracker.backpressureHit)

			fmt.Printf("\nâœ… å…¨éƒ¨å®Œæˆ! æ€»æ•°: %d, æˆåŠŸ: %d, å¤±è´¥: %d, è€—æ—¶: %v\n",
				sent, success, failed, elapsed)
			fmt.Printf("ğŸ“Š èƒŒå‹ç»Ÿè®¡: è§¦å‘ %d æ¬¡\n", backpressureHits)

			return nil
		}

		select {
		case <-ctx.Done():
			return fmt.Errorf("â±ï¸ è¶…æ—¶: å‘é€ %d æ¡ï¼Œå®Œæˆ %d æ¡ (æˆåŠŸ %d, å¤±è´¥ %d), é˜Ÿåˆ—ä¸­ %d æ¡",
				sent, completed, success, failed, queueLen)

		case <-ticker.C:
			// åªåœ¨è¿›åº¦å˜åŒ–æ—¶æ‰“å°
			if completed != lastReported {
				pending := sent - completed
				progress := float64(completed) / float64(sent) * 100
				elapsed := time.Since(startTime)

				// è®¡ç®—é€Ÿç‡
				rate := float64(completed) / elapsed.Seconds()

				// ä¼°ç®—å‰©ä½™æ—¶é—´
				var eta time.Duration
				if rate > 0 {
					eta = time.Duration(float64(sent-completed)/rate) * time.Second
				}

				backpressureHits := atomic.LoadInt64(&p.tracker.backpressureHit)

				fmt.Printf("ğŸ“Š è¿›åº¦: %.1f%% (%d/%d) | æˆåŠŸ: %d, å¤±è´¥: %d | å¾…ç¡®è®¤: %d | é˜Ÿåˆ—: %d | èƒŒå‹: %d æ¬¡ | é€Ÿç‡: %.0f msg/s | è€—æ—¶: %v | ETA: %v\n",
					progress, completed, sent, success, failed, pending, queueLen, backpressureHits, rate,
					elapsed.Round(time.Second), eta.Round(time.Second))

				lastReported = completed
			}
		}
	}
}

// GetStats è·å–ç»Ÿè®¡ä¿¡æ¯
func (p *Producer) GetStats() (sent, success, failed, backpressureHits int64) {
	return p.tracker.GetStats()
}

// Close å…³é—­ Producer
func (p *Producer) Close() {
	p.producer.Close()
}
