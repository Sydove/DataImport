package kafka

import (
	"fmt"

	"github.com/confluentinc/confluent-kafka-go/kafka"
)

// Consumer Kafka Consumer åŒ…è£…
type Consumer struct {
	consumer *kafka.Consumer
	config   ConsumerConfig
}

// NewConsumer åˆ›å»º Consumer
func NewConsumer(config ConsumerConfig, consumerID int) (*Consumer, error) {
	kafkaConfig := getBaseConfig()

	// è®¾ç½® Consumer é…ç½®
	kafkaConfig.SetKey("group.id", config.GroupID)
	kafkaConfig.SetKey("client.id", fmt.Sprintf("consumer-%d", consumerID))
	kafkaConfig.SetKey("auto.offset.reset", config.AutoOffsetReset)
	kafkaConfig.SetKey("go.events.channel.enable", true)
	kafkaConfig.SetKey("go.application.rebalance.enable", true)

	consumer, err := kafka.NewConsumer(kafkaConfig)
	if err != nil {
		return nil, fmt.Errorf("åˆ›å»º Consumer å¤±è´¥: %w", err)
	}

	err = consumer.SubscribeTopics(config.Topics, nil)
	if err != nil {
		consumer.Close()
		return nil, fmt.Errorf("è®¢é˜… Topic å¤±è´¥: %w", err)
	}

	return &Consumer{
		consumer: consumer,
		config:   config,
	}, nil
}

// StartConsuming å¼€å§‹æ¶ˆè´¹æ¶ˆæ¯
func (c *Consumer) StartConsuming(consumerID int, handler func(msg *kafka.Message) error) {
	messageCount := 0
	offsetMap := make(map[kafka.TopicPartition]kafka.Offset)

	for ev := range c.consumer.Events() {
		switch e := ev.(type) {
		case *kafka.Message:
			fmt.Printf("Consumer_%d got msg: %s, partition=%d offset=%d\n",
				consumerID, string(e.Value), e.TopicPartition.Partition, e.TopicPartition.Offset)

			// å¤„ç†æ¶ˆæ¯
			if handler != nil {
				if err := handler(e); err != nil {
					fmt.Printf("âŒ å¤„ç†æ¶ˆæ¯å¤±è´¥: %v\n", err)
				}
			}

			// ä¿å­˜è¯¥åˆ†åŒºæœ€æ–° offset
			tp := kafka.TopicPartition{
				Topic:     e.TopicPartition.Topic,
				Partition: e.TopicPartition.Partition,
			}
			offsetMap[tp] = e.TopicPartition.Offset + 1

			messageCount++

			// è¾¾åˆ°æ‰¹é‡æ•°é‡ï¼Œæäº¤ä¸€æ¬¡
			if messageCount >= c.config.CommitBatchSize {
				var offsets []kafka.TopicPartition

				for tp, off := range offsetMap {
					tp.Offset = off
					offsets = append(offsets, tp)
				}

				_, err := c.consumer.CommitOffsets(offsets)
				if err != nil {
					fmt.Println("âŒ æ‰¹é‡æäº¤å¤±è´¥:", err)
				} else {
					fmt.Println("âœ… æ‰¹é‡æäº¤æˆåŠŸ:", offsets)
				}

				// æ¸…ç©ºè®¡æ•°
				messageCount = 0
			}

		case kafka.AssignedPartitions:
			fmt.Println("ğŸ“Œ åˆ†é…åˆ†åŒº:", e.Partitions)
			c.consumer.Assign(e.Partitions)

		case kafka.RevokedPartitions:
			fmt.Println("ğŸ“Œ å›æ”¶åˆ†åŒº")
			c.consumer.Unassign()

		case kafka.Error:
			fmt.Println("âŒ Kafka Error:", e)
		}
	}
}

// Close å…³é—­ Consumer
func (c *Consumer) Close() error {
	return c.consumer.Close()
}

// GetConsumer è·å–åº•å±‚çš„ kafka.Consumer
func (c *Consumer) GetConsumer() *kafka.Consumer {
	return c.consumer
}
